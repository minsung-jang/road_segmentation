{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Road Segmentations in the images from Google Maps "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] Load \"setting.param\" + * Check the sizes of the raw images in datasets\n",
    "### - input : `setting.param` with the directory where the input images are located\n",
    "### - output: `sm.total_df` with `./summary/(prefix+random_seed)_dataSummary.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting file is loaded ... ./setting.param\n",
      "\n",
      "\n",
      "Try to load the existing file: ./output/test1_32_dataSummary.csv...\n",
      "\n",
      "===== Region [ AZ ] : 162 images =====\n",
      "--- Train # : 116 images\n",
      "--- Valid # : 13 images\n",
      "---  Test # : 33 images\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import modules.setting_module as set_mod\n",
    "sm = set_mod.SettingModule()\n",
    "checkImageSize = False\n",
    "if (checkImageSize):\n",
    "    sm.checkImageSize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] Load the image module and check how to resize images\n",
    "### - input : `sm.total_df` \n",
    "### - output: `sm.total_df` with resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules.image_module as img_mod\n",
    "im = img_mod.ImageModule(sm)\n",
    "\n",
    "import modules.strategy_module as strategy\n",
    "sm.total_df = strategy.Resize(sm.total_df, sm.n_resize, sm.input_img_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3] Batch Grouping and Learning Step Decision: lists of batch information\n",
    "### - input: `sample_df` /\n",
    "### - output: `batch_train`, `batch_valid`, `n_train_steps`, `n_valid_steps`\n",
    "* **Define a batch**\n",
    "\n",
    "```\n",
    "  | (nID[image], crop_x, crop_y) 1          | \n",
    "  | (nID[image], crop_x, crop_y) 2          |\n",
    "  |     ......                              |\n",
    "  | (nID[image], crop_x, crop_y) batch_size |\n",
    "```\n",
    "\n",
    "* **Generate `train` and `valid` batch lists respectively**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size : 12\n",
      "Total Training images : 116\n",
      "Total Validation images : 13\n",
      "Train steps: 10\n",
      "Valid steps: 2\n"
     ]
    }
   ],
   "source": [
    "import modules.batch_module as bm\n",
    "sample_limit = 200\n",
    "bm.getBatchSize(sm.batch_size)\n",
    "batch_train, batch_valid, n_train_steps, n_valid_steps = bm.groupBatch(sm.total_df, sample_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4] Generate batch images from the batch lists\n",
    "### - input: `batch_train`, `batch_valid`\n",
    "### - output: `x_batch`, `y_batch` from `trainGenerator` and `validGenerator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainGenerator():\n",
    "    while True:\n",
    "        \n",
    "        batch_list = batch_train\n",
    "        \n",
    "        for batch in batch_list:\n",
    "            \n",
    "            x_batch, y_batch = bm.generateBatchImages(im, batch, sm.total_df)\n",
    "            \n",
    "            yield x_batch, y_batch\n",
    "\n",
    "def validGenerator():\n",
    "    while True:\n",
    "        \n",
    "        batch_list = batch_valid\n",
    "        \n",
    "        for batch in batch_list:\n",
    "            \n",
    "            x_batch, y_batch = bm.generateBatchImages(im, batch, sm.total_df)\n",
    "\n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5] Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import modules.evaluate_module as em\n",
    "\n",
    "def evalTotalModel(model_name, model, window_size, doResize=True, verbose=True):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    prefix = em.getPrefixString(sm, model_name)\n",
    "    print(\"Saving suffix: \", prefix)\n",
    "        \n",
    "    weight_file_every_epoch = './output/'+prefix+'_updateW.hdf5'\n",
    "    weight_file_final ='./output/'+prefix+'_bestW.h5'\n",
    "    \n",
    "    callbacks = [ReduceLROnPlateau(monitor='val_loss',\n",
    "                                   factor=sm.pl_factor,\n",
    "                                   patience=sm.pl_patience,\n",
    "                                   verbose=1,\n",
    "                                   min_delta=sm.pl_mindelta),\n",
    "                 ModelCheckpoint(monitor='val_loss',\n",
    "                                 filepath=weight_file_every_epoch,\n",
    "                                 save_best_only=True,\n",
    "                                 save_weights_only=True),\n",
    "                 EarlyStopping(monitor='val_loss', \n",
    "                               patience=sm.es_patience,\n",
    "                               min_delta=sm.es_mindelta)]\n",
    "\n",
    "    model.fit_generator(generator=trainGenerator(),\n",
    "                        steps_per_epoch=n_train_steps,\n",
    "                        epochs=sm.epoch,\n",
    "                        verbose=2,\n",
    "                        callbacks=callbacks,\n",
    "                        validation_data=validGenerator(),\n",
    "                        validation_steps=n_valid_steps)\n",
    "\n",
    "    model.save(weight_file_final)\n",
    "\n",
    "    ## Check elapsed time\n",
    "    end_time = time.time()\n",
    "    im.training_time = end_time - start_time\n",
    "    print(\"Elapsed Time: \", im.training_time, \"[sec]\")\n",
    "    \n",
    "    ## Make log file\n",
    "    stat_df = em.saveTestStatistics(im, prefix, model, window_size, doResize, verbose)\n",
    "    \n",
    "    ## Plot histograms\n",
    "    em.plotHistogram(stat_df, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doResize=True\n",
    "verbose=True\n",
    "window_size = im.input_img_size\n",
    "im.pre_process=False\n",
    "\n",
    "from model.u_net import get_unet_256\n",
    "model_unet = get_unet_256()\n",
    "evalTotalModel(\"unet\", model_unet, window_size, doResize, verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# from model.u_net import get_unet_256\n",
    "\n",
    "# model_unet = get_unet_256()\n",
    "# model_unet.load_weights('./output/state13_92_unet_bestW.h5')\n",
    "# prefix = 'mixed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import modules.evaluate_module as em\n",
    "# stat_df = em.saveTestStatistics(im, prefix, model_unet, im.input_img_size, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# nID = 13\n",
    "\n",
    "# img1 =im.loadSingleIMG(nID)\n",
    "# mask1 = im.loadSingleGT(nID)\n",
    "# img2, mask2 = im.loadImageSet(nID)\n",
    "\n",
    "\n",
    "# plt.imshow(img2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
